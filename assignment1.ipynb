{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Enable logging so that all printouts from your program goes directly to a log file named *logfile.txt* which you also need to submit alongside your source code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "#logging config\n",
    "logging.basicConfig(\n",
    "\t\t\t\t\tlevel=logging.DEBUG,\n",
    "\t\t\t\t\tformat='%(levelname)-6s | %(asctime)s | %(message)s',\n",
    "\t\t\t\t\tfilename=f'logfile.txt',\n",
    "\t\t\t\t\tfilemode='w',\n",
    "\t\t\t\t\t)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read A.csv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavelet_transformed_variance</th>\n",
       "      <th>wavelet_transformed_skewness</th>\n",
       "      <th>wavelet_transformed_curtosis</th>\n",
       "      <th>image_entropy</th>\n",
       "      <th>counterfeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.5985</td>\n",
       "      <td>-13.65930</td>\n",
       "      <td>17.6052</td>\n",
       "      <td>-2.49270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0662</td>\n",
       "      <td>0.16967</td>\n",
       "      <td>-1.0054</td>\n",
       "      <td>-0.82975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9922</td>\n",
       "      <td>-4.46760</td>\n",
       "      <td>3.7304</td>\n",
       "      <td>-0.10950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.2134</td>\n",
       "      <td>-2.80600</td>\n",
       "      <td>2.0116</td>\n",
       "      <td>0.67412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.3398</td>\n",
       "      <td>-5.30360</td>\n",
       "      <td>3.8803</td>\n",
       "      <td>-0.70432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wavelet_transformed_variance  wavelet_transformed_skewness  \\\n",
       "0                       -3.5985                     -13.65930   \n",
       "1                       -2.0662                       0.16967   \n",
       "2                        3.9922                      -4.46760   \n",
       "3                        4.2134                      -2.80600   \n",
       "4                        4.3398                      -5.30360   \n",
       "\n",
       "   wavelet_transformed_curtosis  image_entropy  counterfeit  \n",
       "0                       17.6052       -2.49270            1  \n",
       "1                       -1.0054       -0.82975            1  \n",
       "2                        3.7304       -0.10950            0  \n",
       "3                        2.0116        0.67412            0  \n",
       "4                        3.8803       -0.70432            0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('deliverables/A.csv', sep=';', header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wavelet_transformed_variance', 'wavelet_transformed_skewness',\n",
       "       'wavelet_transformed_curtosis', 'image_entropy', 'counterfeit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate dependent variable y as the counterfeit column, and rest of the variables as independent variables (as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1229    0\n",
       "1230    0\n",
       "1231    0\n",
       "1232    1\n",
       "1233    0\n",
       "Name: counterfeit, Length: 1234, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate dependent variable y as the counterfeit column\n",
    "variable_y = df['counterfeit']\n",
    "variable_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 4)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rest of the variables as independent variables (as X).\n",
    "variable_x = df.drop(columns='counterfeit')\n",
    "variable_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Split the dataset, i.e., the (X,y) into training (50%) and test (50%).\n",
    "variable_y = variable_y.values.reshape(-1,1)\n",
    "variable_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset, i.e., the (X,y) into training (50%) and test (50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = len(df)\n",
    "split = nrows//2\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "(617, 1)\n"
     ]
    }
   ],
   "source": [
    "training_set_y = variable_y[:split]\n",
    "print(training_set_y.shape)\n",
    "testing_set_y = variable_y[split:]\n",
    "print(testing_set_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 4)\n",
      "(617, 4)\n"
     ]
    }
   ],
   "source": [
    "training_set_x = variable_x[:split]\n",
    "print(training_set_x.shape)\n",
    "testing_set_x = variable_x[split:]\n",
    "print(testing_set_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the scaler object from *scaler.joblib*. It's already fit to a bunch of training samples. So, don't worry about fit it again. Instead, you may want to use the following lines to use the already fitted scaler object to transform both training and test set. And, do not scale the dependent variable/feature (i.e., y which is the target column counterfeit).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "import joblib\n",
    "scaler = StandardScaler()\n",
    "scaler = joblib.load('deliverables/scaler.joblib') \n",
    "X_train_scaled = scaler.transform(training_set_x) \n",
    "X_test_scaled = scaler.transform(testing_set_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your first classifier with LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m,tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m,multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/venv-assignment1/lib/python3.9/site-packages/sklearn/linear_model/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.linear_model` module implements a variety of linear models.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# See http://scikit-learn.sourceforge.net/modules/sgd.html and\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# http://scikit-learn.sourceforge.net/modules/linear_model.html for\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# complete documentation.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianRidge, ARDRegression\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_least_angle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     Lars,\n\u001b[1;32m     13\u001b[0m     LassoLars,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     LassoLarsIC,\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m~/venv-assignment1/lib/python3.9/site-packages/sklearn/linear_model/_base.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsefuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_variance_axis, inplace_column_scale\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_namespace\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_seq_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayDataset32, CSRDataset32\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_seq_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayDataset64, CSRDataset64\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted, _check_sample_weight\n",
      "File \u001b[0;32msklearn/utils/_seq_dataset.pyx:2\u001b[0m, in \u001b[0;36minit sklearn.utils._seq_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l1',tol=1,solver='liblinear',multi_class='auto',fit_intercept=False,max_iter=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n",
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
