{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Enable logging so that all printouts from your program goes directly to a log file named *logfile.txt* which you also need to submit alongside your source code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "#logging config\n",
    "logging.basicConfig(\n",
    "\t\t\t\t\tlevel=logging.DEBUG,\n",
    "\t\t\t\t\tformat='%(levelname)-6s | %(asctime)s | %(message)s',\n",
    "\t\t\t\t\tfilename=f'logfile.txt',\n",
    "\t\t\t\t\tfilemode='w',\n",
    "\t\t\t\t\t)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read A.csv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavelet_transformed_variance</th>\n",
       "      <th>wavelet_transformed_skewness</th>\n",
       "      <th>wavelet_transformed_curtosis</th>\n",
       "      <th>image_entropy</th>\n",
       "      <th>counterfeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.5985</td>\n",
       "      <td>-13.65930</td>\n",
       "      <td>17.6052</td>\n",
       "      <td>-2.49270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0662</td>\n",
       "      <td>0.16967</td>\n",
       "      <td>-1.0054</td>\n",
       "      <td>-0.82975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9922</td>\n",
       "      <td>-4.46760</td>\n",
       "      <td>3.7304</td>\n",
       "      <td>-0.10950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.2134</td>\n",
       "      <td>-2.80600</td>\n",
       "      <td>2.0116</td>\n",
       "      <td>0.67412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.3398</td>\n",
       "      <td>-5.30360</td>\n",
       "      <td>3.8803</td>\n",
       "      <td>-0.70432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wavelet_transformed_variance  wavelet_transformed_skewness  \\\n",
       "0                       -3.5985                     -13.65930   \n",
       "1                       -2.0662                       0.16967   \n",
       "2                        3.9922                      -4.46760   \n",
       "3                        4.2134                      -2.80600   \n",
       "4                        4.3398                      -5.30360   \n",
       "\n",
       "   wavelet_transformed_curtosis  image_entropy  counterfeit  \n",
       "0                       17.6052       -2.49270            1  \n",
       "1                       -1.0054       -0.82975            1  \n",
       "2                        3.7304       -0.10950            0  \n",
       "3                        2.0116        0.67412            0  \n",
       "4                        3.8803       -0.70432            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('deliverables/A.csv', sep=';', header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wavelet_transformed_variance', 'wavelet_transformed_skewness',\n",
       "       'wavelet_transformed_curtosis', 'image_entropy', 'counterfeit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate dependent variable y as the counterfeit column, and rest of the variables as independent variables (as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1229    0\n",
       "1230    0\n",
       "1231    0\n",
       "1232    1\n",
       "1233    0\n",
       "Name: counterfeit, Length: 1234, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate dependent variable y as the counterfeit column\n",
    "variable_y = df['counterfeit']\n",
    "variable_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rest of the variables as independent variables (as X).\n",
    "variable_x = df.drop(columns='counterfeit')\n",
    "variable_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Split the dataset, i.e., the (X,y) into training (50%) and test (50%).\n",
    "variable_y = variable_y.values.reshape(-1,1)\n",
    "variable_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset, i.e., the (X,y) into training (50%) and test (50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = len(df)\n",
    "split = nrows//2\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "(617, 1)\n"
     ]
    }
   ],
   "source": [
    "training_set_y = variable_y[:split]\n",
    "print(training_set_y.shape)\n",
    "testing_set_y = variable_y[split:]\n",
    "print(testing_set_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 4)\n",
      "(617, 4)\n"
     ]
    }
   ],
   "source": [
    "training_set_x = variable_x[:split]\n",
    "print(training_set_x.shape)\n",
    "testing_set_x = variable_x[split:]\n",
    "print(testing_set_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the scaler object from *scaler.joblib*. It's already fit to a bunch of training samples. So, don't worry about fit it again. Instead, you may want to use the following lines to use the already fitted scaler object to transform both training and test set. And, do not scale the dependent variable/feature (i.e., y which is the target column counterfeit).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "import joblib\n",
    "scaler = StandardScaler()\n",
    "scaler = joblib.load('deliverables/scaler.joblib') \n",
    "X_train_scaled = scaler.transform(training_set_x) \n",
    "X_test_scaled = scaler.transform(testing_set_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your first classifier with LogisticRegression.\n",
    "- Once the model1 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model1.joblib. Please do not submit the joblib file. It's only for your later usage of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = LogisticRegression(penalty='l1',tol=1,solver='liblinear',multi_class='auto',fit_intercept=False,max_iter=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9497568881685575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model1.fit(X_train_scaled,training_set_y)\n",
    "pred1 = model1.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred1)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model1.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your second classifier with KNeighborsClassifier\n",
    "- Once the model2 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model2.joblib. Please do not submit the joblib file. It's only for your later usage of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model2 = KNeighborsClassifier(n_neighbors=3,p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9967585089141004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train_scaled,training_set_y)\n",
    "pred2 = model2.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred2)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model2.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model2, 'model2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Build your third classifier with SVC\n",
    "- Once the model3 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model3.joblib. Please do not submit the joblib file. It's only for your later usage of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model3 = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9918962722852512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model3.fit(X_train_scaled,training_set_y)\n",
    "pred3 = model3.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred3)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model3.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model3, 'model3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your fourth classifier with MLPClassifier\n",
    "- Once the model4 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model4.joblib. Please do not submit the joblib file. It's only for your later usage of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model4 = MLPClassifier(solver='lbfgs',alpha=0.1,hidden_layer_sizes=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1105: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9886547811993517\n"
     ]
    }
   ],
   "source": [
    "model4.fit(X_train_scaled,training_set_y)\n",
    "pred4 = model4.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred4)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model4.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model4, 'model4.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your fifth classifier with DecisionTreeClassifier\n",
    "- Once the model5 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model5.joblib. Please do not submit the joblib file. It's only for your later usage of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9805510534846029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model5 = DecisionTreeClassifier()\n",
    "model5.fit(X_train_scaled,training_set_y)\n",
    "pred5 = model5.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred5)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model5.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model5, 'model5.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your sixth classifier with RandomForestClassifier.\n",
    "- Once the model6 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model6.joblib. Please do not submit the joblib file. It's only for your later usage of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model6 = RandomForestClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9286871961102107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model6.fit(X_train_scaled,training_set_y)\n",
    "pred6 = model6.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred6)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model6.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model6, 'model6.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Build your seventh classifier with XGBClassifier\n",
    "- Once the model7 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model7.joblib. Please do not submit the joblib file. It's only for your later usage of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model7 = XGBClassifier(n_estimators=2,max_depth= 2, learning_rate=1, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9529983792544571\n"
     ]
    }
   ],
   "source": [
    "model7.fit(X_train_scaled,training_set_y)\n",
    "pred7 = model7.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred7)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model7.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model7, 'model7.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your eighth classifier with GaussianNB\n",
    "- Once the model8 object is instantiated, call the fit method on the training split.\n",
    "- Make sure to save the model with joblib library and as a file named model8.joblib. Please do not submit the joblib file. It's only for your later usage of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8476499189627229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalienguyen/venv-assignment1/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model8 = GaussianNB()\n",
    "model8.fit(X_train_scaled,training_set_y)\n",
    "pred8 = model8.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(testing_set_y, pred8)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model8.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model8, 'model8.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Get predictions for the 2 samples in B.csv:\n",
    "    - Have each of the 8 models predict the 2 samples present in the B.csv file. Please note: the true annotations for the two samples are not present in the file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavelet_transformed_variance</th>\n",
       "      <th>wavelet_transformed_skewness</th>\n",
       "      <th>wavelet_transformed_curtosis</th>\n",
       "      <th>image_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.97</td>\n",
       "      <td>10.17</td>\n",
       "      <td>-4.11</td>\n",
       "      <td>-4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.90</td>\n",
       "      <td>4.77</td>\n",
       "      <td>-4.84</td>\n",
       "      <td>-5.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wavelet_transformed_variance  wavelet_transformed_skewness  \\\n",
       "0                          3.97                         10.17   \n",
       "1                          0.90                          4.77   \n",
       "\n",
       "   wavelet_transformed_curtosis  image_entropy  \n",
       "0                         -4.11          -4.61  \n",
       "1                         -4.84          -5.59  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B = pd.read_csv('deliverables/B.csv',sep=';',header=0)\n",
    "df_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the columns in B are the same as variable_x\n",
    "B_variable_x = df_B\n",
    "B_variable_x_scaled = scaler.transform(B_variable_x)\n",
    "B_variable_x_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 predicted [0 0]\n",
      "Model 2 predicted [0 1]\n",
      "Model 3 predicted [0 1]\n",
      "Model 4 predicted [0 1]\n",
      "Model 5 predicted [0 1]\n",
      "Model 6 predicted [0 1]\n",
      "Model 7 predicted [0 1]\n",
      "Model 8 predicted [0 0]\n"
     ]
    }
   ],
   "source": [
    "predicted1 = model1.predict(B_variable_x_scaled)\n",
    "print(\"Model 1 predicted\",predicted1)\n",
    "predicted2 = model2.predict(B_variable_x_scaled)\n",
    "print(\"Model 2 predicted\",predicted2)\n",
    "predicted3 = model3.predict(B_variable_x_scaled)\n",
    "print(\"Model 3 predicted\",predicted3)\n",
    "predicted4 = model4.predict(B_variable_x_scaled)\n",
    "print(\"Model 4 predicted\",predicted4)\n",
    "predicted5 = model5.predict(B_variable_x_scaled)\n",
    "print(\"Model 5 predicted\",predicted5)\n",
    "predicted6 = model6.predict(B_variable_x_scaled)\n",
    "print(\"Model 6 predicted\",predicted6)\n",
    "predicted7 = model7.predict(B_variable_x_scaled)\n",
    "print(\"Model 7 predicted\",predicted7)\n",
    "predicted8 = model8.predict(B_variable_x_scaled)\n",
    "print(\"Model 8 predicted\",predicted8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consensus prediction for sample 1: 0\n",
      "Consensus prediction for sample 2: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Combine predictions for each sample\n",
    "predictions_sample1 = [predicted1[0], predicted2[0], predicted3[0], predicted4[0], predicted5[0], predicted6[0], predicted7[0], predicted8[0]]\n",
    "predictions_sample2 = [predicted1[1], predicted2[1], predicted3[1], predicted4[1], predicted5[1], predicted6[1], predicted7[1], predicted8[1]]\n",
    "\n",
    "# Use majority voting to determine the consensus predictions\n",
    "consensus_sample1 = Counter(predictions_sample1).most_common(1)[0][0]\n",
    "consensus_sample2 = Counter(predictions_sample2).most_common(1)[0][0]\n",
    "\n",
    "# Print consensus predictions\n",
    "print(\"Consensus prediction for sample 1:\", consensus_sample1)\n",
    "print(\"Consensus prediction for sample 2:\", consensus_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy, Precision, and Recall on B.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model1: 0.9497568881685575\n",
      "Precision for model1: 0.9187279151943463\n",
      "Recall for model1: 0.9701492537313433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
    "pred1 = pred1.reshape(-1,1)\n",
    "\n",
    "print(pred1.shape)\n",
    "print(\"Accuracy for model1:\", accuracy_score(testing_set_y, pred1))\n",
    "print(\"Precision for model1:\", precision_score(testing_set_y, pred1, average=\"binary\")) \n",
    "print('Recall for model1:', recall_score(testing_set_y, pred1, average=\"binary\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model2: 0.9967585089141004\n",
      "Precision for mode2: 0.9925925925925926\n",
      "Recall for model2: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred2 = pred2.reshape(-1,1)\n",
    "print(pred2.shape)\n",
    "print(\"Accuracy for model2:\", accuracy_score(testing_set_y, pred2))\n",
    "print(\"Precision for mode2:\", precision_score(testing_set_y, pred2, average=\"binary\")) \n",
    "print('Recall for model2:', recall_score(testing_set_y, pred2, average=\"binary\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model3: 0.9918962722852512\n",
      "Precision for model3: 0.9816849816849816\n",
      "Recall for model3: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred3 = pred3.reshape(-1,1)\n",
    "print(pred3.shape)\n",
    "print(\"Accuracy for model3:\", accuracy_score(testing_set_y, pred3))\n",
    "print(\"Precision for model3:\", precision_score(testing_set_y, pred3, average=\"binary\")) \n",
    "print('Recall for model3:', recall_score(testing_set_y, pred3, average=\"binary\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model4: 0.9886547811993517\n",
      "Precision for model4: 0.9887640449438202\n",
      "Recall for model4: 0.9850746268656716\n"
     ]
    }
   ],
   "source": [
    "pred4 = pred4.reshape(-1,1)\n",
    "print(pred4.shape)\n",
    "print(\"Accuracy for model4:\", accuracy_score(testing_set_y, pred4))\n",
    "print(\"Precision for model4:\", precision_score(testing_set_y, pred4, average=\"binary\")) \n",
    "print('Recall for model4:', recall_score(testing_set_y, pred4, average=\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model5: 0.9805510534846029\n",
      "Precision for model5: 0.9637681159420289\n",
      "Recall for model5: 0.9925373134328358\n"
     ]
    }
   ],
   "source": [
    "pred5 = pred5.reshape(-1,1)\n",
    "print(pred5.shape)\n",
    "print(\"Accuracy for model5:\", accuracy_score(testing_set_y, pred5))\n",
    "print(\"Precision for model5:\", precision_score(testing_set_y, pred5, average=\"binary\")) \n",
    "print('Recall for model5:', recall_score(testing_set_y, pred5, average=\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model6: 0.9286871961102107\n",
      "Precision for model6: 0.9444444444444444\n",
      "Recall for model6: 0.8880597014925373\n"
     ]
    }
   ],
   "source": [
    "pred6 = pred6.reshape(-1,1)\n",
    "print(pred6.shape)\n",
    "print(\"Accuracy for model6:\", accuracy_score(testing_set_y, pred6))\n",
    "print(\"Precision for model6:\", precision_score(testing_set_y, pred6, average=\"binary\")) \n",
    "print('Recall for model6:', recall_score(testing_set_y, pred6, average=\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model7: 0.9529983792544571\n",
      "Precision for model7: 0.947565543071161\n",
      "Recall for model7: 0.9440298507462687\n"
     ]
    }
   ],
   "source": [
    "pred7 = pred7.reshape(-1,1)\n",
    "print(pred7.shape)\n",
    "print(\"Accuracy for model7:\", accuracy_score(testing_set_y, pred7))\n",
    "print(\"Precision for model7:\", precision_score(testing_set_y, pred7, average=\"binary\")) \n",
    "print('Recall for model7:', recall_score(testing_set_y, pred7, average=\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 1)\n",
      "Accuracy for model8: 0.8476499189627229\n",
      "Precision for model8: 0.8452380952380952\n",
      "Recall for model8: 0.7947761194029851\n"
     ]
    }
   ],
   "source": [
    "pred8 = pred8.reshape(-1,1)\n",
    "print(pred8.shape)\n",
    "print(\"Accuracy for model8:\", accuracy_score(testing_set_y, pred8))\n",
    "print(\"Precision for model8:\", precision_score(testing_set_y, pred8, average=\"binary\")) \n",
    "print('Recall for model8:', recall_score(testing_set_y, pred8, average=\"binary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate models based on C.csv dataset:\n",
    "    - C.csv contains annotated samples. Use the target annotations to evaluate all the 8 models.\n",
    "    - Please report accuracy, precision, recall, f1-score, false-discovery rate, matthews correlation coefficient\n",
    "    - Please don't forget to scale the samples present in this dataset prior to sending to the models for prediction.\n",
    "    - Also, comment which model performs the best in each of the 6 evaluation metrics.\n",
    "    - Also, comment which model do you think is acceptable to deploy in a real bank. Justify your reasoning. Also, avoid answers like none is acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavelet_transformed_variance</th>\n",
       "      <th>wavelet_transformed_skewness</th>\n",
       "      <th>wavelet_transformed_curtosis</th>\n",
       "      <th>image_entropy</th>\n",
       "      <th>counterfeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.8272</td>\n",
       "      <td>3.06870</td>\n",
       "      <td>0.68604</td>\n",
       "      <td>0.80731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.8969</td>\n",
       "      <td>0.70768</td>\n",
       "      <td>2.29000</td>\n",
       "      <td>1.86630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.1464</td>\n",
       "      <td>6.07950</td>\n",
       "      <td>-0.57780</td>\n",
       "      <td>-2.23020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.1405</td>\n",
       "      <td>-0.16762</td>\n",
       "      <td>1.32100</td>\n",
       "      <td>-0.20906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.8554</td>\n",
       "      <td>-5.90370</td>\n",
       "      <td>10.98180</td>\n",
       "      <td>-0.82199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wavelet_transformed_variance  wavelet_transformed_skewness  \\\n",
       "0                        4.8272                       3.06870   \n",
       "1                        2.8969                       0.70768   \n",
       "2                        2.1464                       6.07950   \n",
       "3                       -2.1405                      -0.16762   \n",
       "4                       -4.8554                      -5.90370   \n",
       "\n",
       "   wavelet_transformed_curtosis  image_entropy  counterfeit  \n",
       "0                       0.68604        0.80731            0  \n",
       "1                       2.29000        1.86630            0  \n",
       "2                      -0.57780       -2.23020            0  \n",
       "3                       1.32100       -0.20906            1  \n",
       "4                      10.98180       -0.82199            1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_df = pd.read_csv('deliverables/C.csv', sep=';', header=0)\n",
    "C_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 5)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 4)\n",
      "(136, 1)\n"
     ]
    }
   ],
   "source": [
    "C_variable_x = C_df.drop(columns=['counterfeit'])\n",
    "C_variable_y = C_df['counterfeit']\n",
    "C_variable_y = C_variable_y.values.reshape(-1,1)\n",
    "C_variable_x_scaled = scaler.transform(C_variable_x)\n",
    "print(C_variable_x_scaled.shape)\n",
    "print(C_variable_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_model1 = model1.predict(C_variable_x_scaled)\n",
    "C_model2 = model2.predict(C_variable_x_scaled)\n",
    "C_model3 = model3.predict(C_variable_x_scaled)\n",
    "C_model4 = model4.predict(C_variable_x_scaled)\n",
    "C_model5 = model5.predict(C_variable_x_scaled)\n",
    "C_model6 = model6.predict(C_variable_x_scaled)\n",
    "C_model7 = model7.predict(C_variable_x_scaled)\n",
    "C_model8 = model8.predict(C_variable_x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 1)\n",
      "(136, 1)\n",
      "(136, 1)\n",
      "(136, 1)\n",
      "(136, 1)\n",
      "(136, 1)\n",
      "(136, 1)\n",
      "(136, 1)\n"
     ]
    }
   ],
   "source": [
    "C_model1 = C_model1.reshape(-1,1)\n",
    "C_model2 = C_model2.reshape(-1,1)\n",
    "C_model3 = C_model3.reshape(-1,1)\n",
    "C_model4 = C_model4.reshape(-1,1)\n",
    "C_model5 = C_model5.reshape(-1,1)\n",
    "C_model6 = C_model6.reshape(-1,1)\n",
    "C_model7 = C_model7.reshape(-1,1)\n",
    "C_model8 = C_model8.reshape(-1,1)\n",
    "print(C_model1.shape)\n",
    "print(C_model2.shape)\n",
    "print(C_model3.shape)\n",
    "print(C_model4.shape)\n",
    "print(C_model5.shape)\n",
    "print(C_model6.shape)\n",
    "print(C_model7.shape)\n",
    "print(C_model8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1 on C.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy on set C: 0.9485294117647058\n",
      "Model 1 Precision on set C: 0.896551724137931\n",
      "Model 1 Recall on set C: 0.9811320754716981\n",
      "Model 1 F1-Score on set C: 0.9369369369369369\n",
      "Model 1 False-Discovery Rate on set C: 0.10344827586206895\n",
      "Model 1 Matthews Correlation Coefficient on set C: 0.8961991149115913\n"
     ]
    }
   ],
   "source": [
    "# report accuracy, precision, recall, f1-score, false-discovery rate, matthews correlation coefficient\n",
    "# TP = label set (variable_y/counterfeit)\n",
    "# FP = features set (variable_X)\n",
    "\n",
    "accuracy1 = accuracy_score(C_variable_y, C_model1)\n",
    "precision1 = precision_score(C_variable_y, C_model1, average=\"binary\")\n",
    "recall1 = recall_score(C_variable_y, C_model1, average=\"binary\")\n",
    "f1score1 = f1_score(C_variable_y, C_model1, average=\"binary\")\n",
    "FDR1 = 1 - precision1\n",
    "MCC1 = matthews_corrcoef(C_variable_y, C_model1)\n",
    "\n",
    "print(\"Model 1 Accuracy on set C:\", accuracy1)\n",
    "print(\"Model 1 Precision on set C:\", precision1)\n",
    "print(\"Model 1 Recall on set C:\", recall1)\n",
    "print(\"Model 1 F1-Score on set C:\", f1score1)\n",
    "print(\"Model 1 False-Discovery Rate on set C:\", FDR1)\n",
    "print(\"Model 1 Matthews Correlation Coefficient on set C:\", MCC1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 2 on C.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Accuracy on set C: 1.0\n",
      "Model 2 Precision on set C: 1.0\n",
      "Model 2 Recall on set C: 1.0\n",
      "Model 2 F1-Score on set C: 1.0\n",
      "Model 2 False-Discovery Rate on set C: 0.0\n",
      "Model 2 Matthews Correlation Coefficient on set C: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = accuracy_score(C_variable_y, C_model2)\n",
    "precision2 = precision_score(C_variable_y, C_model2, average=\"binary\")\n",
    "recall2 = recall_score(C_variable_y, C_model2, average=\"binary\")\n",
    "f1score2 = f1_score(C_variable_y, C_model2, average=\"binary\")\n",
    "FDR2 = 1 - precision2\n",
    "MCC2 = matthews_corrcoef(C_variable_y, C_model2)\n",
    "\n",
    "print(\"Model 2 Accuracy on set C:\", accuracy2)\n",
    "print(\"Model 2 Precision on set C:\", precision2)\n",
    "print(\"Model 2 Recall on set C:\", recall2)\n",
    "print(\"Model 2 F1-Score on set C:\", f1score2)\n",
    "print(\"Model 2 False-Discovery Rate on set C:\", FDR2)\n",
    "print(\"Model 2 Matthews Correlation Coefficient on set C:\", MCC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Accuracy on set C: 1.0\n",
      "Model 3 Precision on set C: 1.0\n",
      "Model 3 Recall on set C: 1.0\n",
      "Model 3 F1-Score on set C: 1.0\n",
      "Model 3 False-Discovery Rate on set C: 0.0\n",
      "Model 3 Matthews Correlation Coefficient on set C: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy3 = accuracy_score(C_variable_y, C_model3)\n",
    "precision3 = precision_score(C_variable_y, C_model3, average=\"binary\")\n",
    "recall3 = recall_score(C_variable_y, C_model3, average=\"binary\")\n",
    "f1score3 = f1_score(C_variable_y, C_model3, average=\"binary\")\n",
    "FDR3 = 1 - precision3\n",
    "MCC3 = matthews_corrcoef(C_variable_y, C_model3)\n",
    "\n",
    "print(\"Model 3 Accuracy on set C:\", accuracy3)\n",
    "print(\"Model 3 Precision on set C:\", precision3)\n",
    "print(\"Model 3 Recall on set C:\", recall3)\n",
    "print(\"Model 3 F1-Score on set C:\", f1score3)\n",
    "print(\"Model 3 False-Discovery Rate on set C:\", FDR3)\n",
    "print(\"Model 3 Matthews Correlation Coefficient on set C:\", MCC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 Accuracy on set C: 1.0\n",
      "Model 4 Precision on set C: 1.0\n",
      "Model 4 Recall on set C: 1.0\n",
      "Model 4 F1-Score on set C: 1.0\n",
      "Model 4 False-Discovery Rate on set C: 0.0\n",
      "Model 4 Matthews Correlation Coefficient on set C: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy4 = accuracy_score(C_variable_y, C_model4)\n",
    "precision4 = precision_score(C_variable_y, C_model4, average=\"binary\")\n",
    "recall4 = recall_score(C_variable_y, C_model4, average=\"binary\")\n",
    "f1score4 = f1_score(C_variable_y, C_model4, average=\"binary\")\n",
    "FDR4 = 1 - precision4\n",
    "MCC4 = matthews_corrcoef(C_variable_y, C_model4)\n",
    "\n",
    "print(\"Model 4 Accuracy on set C:\", accuracy4)\n",
    "print(\"Model 4 Precision on set C:\", precision4)\n",
    "print(\"Model 4 Recall on set C:\", recall4)\n",
    "print(\"Model 4 F1-Score on set C:\", f1score4)\n",
    "print(\"Model 4 False-Discovery Rate on set C:\", FDR4)\n",
    "print(\"Model 4 Matthews Correlation Coefficient on set C:\", MCC4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 Accuracy on set C: 0.9779411764705882\n",
      "Model 5 Precision on set C: 0.9629629629629629\n",
      "Model 5 Recall on set C: 0.9811320754716981\n",
      "Model 5 F1-Score on set C: 0.9719626168224299\n",
      "Model 5 False-Discovery Rate on set C: 0.03703703703703709\n",
      "Model 5 Matthews Correlation Coefficient on set C: 0.95389661739912\n"
     ]
    }
   ],
   "source": [
    "accuracy5 = accuracy_score(C_variable_y, C_model5)\n",
    "precision5 = precision_score(C_variable_y, C_model5, average=\"binary\")\n",
    "recall5 = recall_score(C_variable_y, C_model5, average=\"binary\")\n",
    "f1score5 = f1_score(C_variable_y, C_model5, average=\"binary\")\n",
    "FDR5 = 1 - precision5\n",
    "MCC5 = matthews_corrcoef(C_variable_y, C_model5)\n",
    "\n",
    "print(\"Model 5 Accuracy on set C:\", accuracy5)\n",
    "print(\"Model 5 Precision on set C:\", precision5)\n",
    "print(\"Model 5 Recall on set C:\", recall5)\n",
    "print(\"Model 5 F1-Score on set C:\", f1score5)\n",
    "print(\"Model 5 False-Discovery Rate on set C:\", FDR5)\n",
    "print(\"Model 5 Matthews Correlation Coefficient on set C:\", MCC5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 Accuracy on set C: 0.9338235294117647\n",
      "Model 6 Precision on set C: 0.94\n",
      "Model 6 Recall on set C: 0.8867924528301887\n",
      "Model 6 F1-Score on set C: 0.912621359223301\n",
      "Model 6 False-Discovery Rate on set C: 0.06000000000000005\n",
      "Model 6 Matthews Correlation Coefficient on set C: 0.8603844930708776\n"
     ]
    }
   ],
   "source": [
    "accuracy6 = accuracy_score(C_variable_y, C_model6)\n",
    "precision6 = precision_score(C_variable_y, C_model6, average=\"binary\")\n",
    "recall6 = recall_score(C_variable_y, C_model6, average=\"binary\")\n",
    "f1score6 = f1_score(C_variable_y, C_model6, average=\"binary\")\n",
    "FDR6 = 1 - precision6\n",
    "MCC6 = matthews_corrcoef(C_variable_y, C_model6)\n",
    "\n",
    "print(\"Model 6 Accuracy on set C:\", accuracy6)\n",
    "print(\"Model 6 Precision on set C:\", precision6)\n",
    "print(\"Model 6 Recall on set C:\", recall6)\n",
    "print(\"Model 6 F1-Score on set C:\", f1score6)\n",
    "print(\"Model 6 False-Discovery Rate on set C:\", FDR6)\n",
    "print(\"Model 6 Matthews Correlation Coefficient on set C:\", MCC6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7 Accuracy on set C: 0.9558823529411765\n",
      "Model 7 Precision on set C: 0.9122807017543859\n",
      "Model 7 Recall on set C: 0.9811320754716981\n",
      "Model 7 F1-Score on set C: 0.9454545454545454\n",
      "Model 7 False-Discovery Rate on set C: 0.08771929824561409\n",
      "Model 7 Matthews Correlation Coefficient on set C: 0.9101946715019502\n"
     ]
    }
   ],
   "source": [
    "accuracy7 = accuracy_score(C_variable_y, C_model7)\n",
    "precision7 = precision_score(C_variable_y, C_model7, average=\"binary\")\n",
    "recall7 = recall_score(C_variable_y, C_model7, average=\"binary\")\n",
    "f1score7 = f1_score(C_variable_y, C_model7, average=\"binary\")\n",
    "FDR7 = 1 - precision7\n",
    "MCC7 = matthews_corrcoef(C_variable_y, C_model7)\n",
    "\n",
    "print(\"Model 7 Accuracy on set C:\", accuracy7)\n",
    "print(\"Model 7 Precision on set C:\", precision7)\n",
    "print(\"Model 7 Recall on set C:\", recall7)\n",
    "print(\"Model 7 F1-Score on set C:\", f1score7)\n",
    "print(\"Model 7 False-Discovery Rate on set C:\", FDR7)\n",
    "print(\"Model 7 Matthews Correlation Coefficient on set C:\", MCC7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8 Accuracy on set C: 0.8676470588235294\n",
      "Model 8 Precision on set C: 0.8571428571428571\n",
      "Model 8 Recall on set C: 0.7924528301886793\n",
      "Model 8 F1-Score on set C: 0.8235294117647058\n",
      "Model 8 False-Discovery Rate on set C: 0.1428571428571429\n",
      "Model 8 Matthews Correlation Coefficient on set C: 0.7193221003093736\n"
     ]
    }
   ],
   "source": [
    "accuracy8 = accuracy_score(C_variable_y, C_model8)\n",
    "precision8 = precision_score(C_variable_y, C_model8, average=\"binary\")\n",
    "recall8 = recall_score(C_variable_y, C_model8, average=\"binary\")\n",
    "f1score8 = f1_score(C_variable_y, C_model8, average=\"binary\")\n",
    "FDR8 = 1 - precision8\n",
    "MCC8 = matthews_corrcoef(C_variable_y, C_model8)\n",
    "\n",
    "print(\"Model 8 Accuracy on set C:\", accuracy8)\n",
    "print(\"Model 8 Precision on set C:\", precision8)\n",
    "print(\"Model 8 Recall on set C:\", recall8)\n",
    "print(\"Model 8 F1-Score on set C:\", f1score8)\n",
    "print(\"Model 8 False-Discovery Rate on set C:\", FDR8)\n",
    "print(\"Model 8 Matthews Correlation Coefficient on set C:\", MCC8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Conclusion\n",
    "- Comment which model performs the best in each of the 6 evaluation metrics.\n",
    "- Comment which model do you think is acceptable to deploy in a real bank. Justify your reasoning. Also, avoid answers like none is acceptable. \n",
    "\n",
    "\n",
    "The models that performed the best with all 6 evaluation metrics were 2,3 and 4 which were classfied with KNeighborsClassifier, SVC, and MLPClassifier. Since all three had the same evaluation metrics, it can be concluded that the best models are classified KNeighborsClassifier, SVC, MLPClassifier. \n",
    "\n",
    "model 2 had the best accuracy rate on set A.csv and B.csv\n",
    "\n",
    "Overall the best model was **Model 2** which was classified with SVC. This is because it had the best evaluation metric on all CSV files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
